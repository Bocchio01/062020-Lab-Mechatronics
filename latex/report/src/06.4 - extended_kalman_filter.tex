\subsection{Extended Kalman Filter}
\label{subsec:extended_kalman_filter}

The extended Kalman filter (EKF) is the nonlinear version of the Kalman filter which linearizes about an estimate of the current mean and covariance. It assumes a linearized system model of the form:

\begin{equation}
    \begin{aligned}
        \dot{x} & = A x + B u + w \\
        y       & = C x + D u + v
    \end{aligned}
\end{equation}

Where $x$ is the state vector, $u$ is the control input, $y$ is the measurement, $A$ is the state transition matrix, $B$ is the control input matrix, $C$ is the observation matrix and $w$ and $v$ are the process and measurement noise, respectively.
Among the assumptions of the Kalman filter, both the process noise and the measurement noise are assumed to be zero-mean Gaussian white noise with known covariances $Q$ and $R$. At each iteration, the system is linearized around the current estimated state. The main disadvantage is that, due to the online linearization, the computational cost is higher with respect to the basic Kalman filter.
The Kalman gain is the same of the basic filter:
\begin{equation}
    K = P^- H^T (H P^- H^T + R)^{-1}
    \label{eq:kalman_gain_extended}
\end{equation}

A key limitation of the EKF is that, unlike its linear counterpart, it is not inherently an optimal estimator. It only becomes optimal in cases where both the measurement model and the state transition model are linear, as under those conditions, the EKF effectively reduces to the standard Kalman filter. Furthermore, if the initial state estimate is inaccurate or if the process is poorly modeled, the EKF may diverge rapidly because of the inherent approximations introduced by its linearization approach. Another challenge associated with the EKF is that its estimated covariance matrix often underrepresents the true covariance matrix. This underestimation can lead to statistical inconsistency unless corrective measures are applied, such as the introduction of "stabilizing noise."
However the extended Kalman filter can give reasonable performance and is arguably the de facto standard in navigation systems and GPS.

\paragraph{Design}
As we have seen in the Luenberger observer and Kalman filter design, the poles of the observer are given by the eigenvalues of the matrix $A - KC$. The observer is stable if the poles are placed in the left half-plane of the complex plane.
The extended Kalman gain $K$ can be computed using Equation \ref{eq:kalman_gain_extended}. The main difference is that $K$ is different at each iteration step.

